[H1] Azure AI Speech Service Implementation Guide## ProblemYou need implement application recognize spoken commands respond synthesized speech output.## Solution AzureUse Azure AI Speech service:- Speech-to-Text API recognizing speech- Text-to-Speech API generating speech output## Components required- Azure AI Speech resource (created via Azure Portal)- Visual Studio Code- Language SDK: - Microsoft.CognitiveServices.Speech NuGet package (C#) - azure-cognitiveservices-speech pip package (Python)- (Optional) Audio input/output libraries: - System.Media.SoundPlayer (C#) - playsound (Python)- Microphone (or use audio file alternative)GitHub repository: Architecture / Development### 1. Provision Azure AI Speech resourceAzure Portal Azure AI Services Create Speech ServiceRequired settings: Subscription, Resource group, Region, Name, Pricing tierAfter deployment: Get Key Region Keys Endpoint### 2. Set development environment- Clone repo: mslearn-ai-language- Open VS Code trust project
Subscription, Resource group, Region, Name, Pricing tierAfter deployment: Get Key Region Keys Endpoint### 2. Set development environment- Clone repo: mslearn-ai-language- Open VS Code trust project prompted- Use Labfiles/07-speech choose CSharp Python speaking-clock folder### 3. Install SDKC#bashdotnet add package Microsoft.CognitiveServices.Speech --version 1.30.0Pythonbashpip install azure-cognitiveservices-speech==1.30.0### 4. Configure appEdit configuration file:- C#: appsettings.json- Python: .envAdd key region### 5. Initialize SDKC#:csharpusing Microsoft.CognitiveServices.Speech;using Microsoft.CognitiveServices.Speech.Audio;speechConfig = SpeechConfig.FromSubscription(aiSvcKey, aiSvcRegion);speechConfig.SpeechSynthesisVoiceName = "en-US-AriaNeural";Python:pythonimport azure.cognitiveservices.speech speech_sdkspeech_config = speech_sdk.SpeechConfig(ai_key, ai_region)speech_config.speech_synthesis_voice_name = "en-US-AriaNeural"### 6. Recognize speech
azure.cognitiveservices.speech speech_sdkspeech_config = speech_sdk.SpeechConfig(ai_key, ai_region)speech_config.speech_synthesis_voice_name = "en-US-AriaNeural"### 6. Recognize speech inputMicrophoneC#:csharpusing AudioConfig audioConfig = AudioConfig.FromDefaultMicrophoneInput();using SpeechRecognizer speechRecognizer = new SpeechRecognizer(speechConfig, audioConfig);Python:pythonaudio_config = speech_sdk.AudioConfig(use_default_microphone=True)speech_recognizer = speech_sdk.SpeechRecognizer(speech_config, audio_config)Or audio fileInstall playback:C#:bashdotnet add package System.Windows.Extensions --version 4.6.0Python:bashpip install playsound==1.2.2Add code:C#:csharpstring audioFile = "time.wav";SoundPlayer wavPlayer = new SoundPlayer(audioFile);wavPlayer.Play();using AudioConfig audioConfig = AudioConfig.FromWavFileInput(audioFile);Python:pythonfrom playsound import playsoundaudioFile = os.getcwd() + '\\time.wav'playsound(audioFile)audio_config =
AudioConfig audioConfig = AudioConfig.FromWavFileInput(audioFile);Python:pythonfrom playsound import playsoundaudioFile = os.getcwd() + '\\time.wav'playsound(audioFile)audio_config = speech_sdk.AudioConfig(filename=audioFile)### 7. Transcribe speechC#:csharpSpeechRecognitionResult speech = await speechRecognizer.RecognizeOnceAsync();if (speech.Reason == ResultReason.RecognizedSpeech) { command = speech.Text; Console.WriteLine(command);}Python:pythonspeech = speech_recognizer.recognize_once_async().get()if speech.reason == speech_sdk.ResultReason.RecognizedSpeech: command = speech.text print(command)### 8. Synthesize speechC#:csharpusing SpeechSynthesizer speechSynthesizer = new SpeechSynthesizer(speechConfig);SpeechSynthesisResult speak = await speechSynthesizer.SpeakTextAsync(responseText);Python:pythonspeech_synthesizer = speech_sdk.SpeechSynthesizer(speech_config)speak = speech_synthesizer.speak_text_async(response_text).get()### 9. Use alternative
= speech_sdk.SpeechSynthesizer(speech_config)speak = speech_synthesizer.speak_text_async(response_text).get()### 9. Use alternative voiceC#:csharpspeechConfig.SpeechSynthesisVoiceName = "en-GB-LibbyNeural";Python:pythonspeech_config.speech_synthesis_voice_name = 'en-GB-LibbyNeural'### 10. Use SSMLC#:```csharpstring responseSsml = $@"<speak version='1.0' xmlns=' xml:lang='en-US'
