[H1] Explore foundation models capabilities Azure AI Foundry## Problem StatementBuilding generative AI applications requires:- Selecting right foundation model thousands available- Understanding model capabilities limitations- Deploying models efficiently production use- Optimizing model performance prompt engineering- Scaling solutions real-world workloads### Key Challenges:- How choose LLMs vs SLMs?- When use proprietary vs open-source models?- How evaluate model precision performance?- How optimize outputs prompt engineering?- How deploy scale models effectively?## Solution AzureAzure AI Foundryprovides comprehensive model catalog tools exploration, deployment, optimization foundation models. The platform supports proprietary models (GPT-4, Mistral) open-source alternatives Hugging Face, enabling developers build scalable generative AI applications.## Required Components### Foundation Model TypesLanguage Models- Generate, understand, interact natural language- Common use cases:
Face, enabling developers build scalable generative AI applications.## Required Components### Foundation Model TypesLanguage Models- Generate, understand, interact natural language- Common use cases: speech-to-text, translation, text classification, entity extraction, summarization, Q&A, reasoningModel Categories-Large Language Models (LLMs): GPT-4, Mistral Large, Llama3 70B - deep reasoning complex content-Small Language Models (SLMs): Phi3, Mistral OSS, Llama3 8B - efficient cost-effective-Chat Completion Models: GPT-4, Mistral Large - generate contextual text responses-Reasoning Models: DeepSeek-R1, o1 - enhanced performance math, coding, science-Multi-Modal Models: GPT-4o, Phi3-vision - process text images-Image Generation: DALL-E 3, Stability AI - create visuals text-Embedding Models: Ada, Cohere - convert text numerical representations-Regional/Domain-Specific: Core42 JAIS (Arabic), NorlaTimeGEN-1 (time series)### Model Catalogs-Hugging Face: Vast catalog open-source
Models: Ada, Cohere - convert text numerical representations-Regional/Domain-Specific: Core42 JAIS (Arabic), NorlaTimeGEN-1 (time series)### Model Catalogs-Hugging Face: Vast catalog open-source models-GitHub: Access via GitHub Marketplace Copilot-Azure AI Foundry: Comprehensive catalog deployment tools## Architecture & Development### Model Selection FrameworkStep 1: Can AI solve use case?- Explore available models three catalogs- Filter deploy models based needs- Test different model typesStep 2: How I select best model?Evaluation Criteria:-Task Type: Text vs multi-modal requirements-Precision: Base model vs fine-tuned specific skills-Openness: Fine-tuning capability requirements-Deployment: Local vs serverless endpoint needsStep 3: Can I scale real-world workloads?Scaling Considerations:- Model deployment strategy- Model monitoring optimization- Prompt management- Model lifecycle (GenAIOps)### Performance EvaluationModel Benchmarks:| Benchmark | Description
Considerations:- Model deployment strategy- Model monitoring optimization- Prompt management- Model lifecycle (GenAIOps)### Performance EvaluationModel Benchmarks:| Benchmark | Description ||-----------|-------------||Accuracy| Compares generated text correct answers (1 exact match, 0 otherwise) ||Coherence| Measures output flows smoothly resembles human language ||Fluency| Assesses grammatical rules, syntax, vocabulary usage ||Groundedness| Measures alignment generated answers input data ||GPT Similarity| Semantic similarity ground truth AI predictions ||Quality Index| Aggregate score 0-1, higher better ||Cost| Price per token model usage |Evaluation Methods:- Manual evaluations initial quality assessment- Automated evaluations using metrics (precision, recall, F1 score)- Traditional ML metrics + AI-assisted metrics### Model DeploymentDeployment Process:1. Select model catalog2. Deploy endpoint (creates unique URI key)3. Send API requests endpoint4. Receive process
Traditional ML metrics + AI-assisted metrics### Model DeploymentDeployment Process:1. Select model catalog2. Deploy endpoint (creates unique URI key)3. Send API requests endpoint4. Receive process responsesDeployment Options:| Service | Supported Models | Hosting | Cost Model | Inferencing ||---------|-----------------|---------|------------|-------------||Azure OpenAI Service| Azure OpenAI models | Azure OpenAI resource | - | Token-based billing ||Azure AI Foundry Models| Flagship models (OpenAI + MaaS) | Azure AI Services resource | - | Token-based billing ||Serverless compute| MaaS service models | AI Project resource | Minimal endpoint cost | Token-based billing ||Managed compute| Open custom models | AI Project resource | Charged per minute | - |### Prompt Engineering OptimizationCore Patterns:1.Persona Instructions: "Act seasoned marketing professional"2.Better Questions: Guide model suggest clarifying questions3.Format Specification: Provide templates output
OptimizationCore Patterns:1.Persona Instructions: "Act seasoned marketing professional"2.Better Questions: Guide model suggest clarifying questions3.Format Specification: Provide templates output structure4.Reasoning Explanation: Use chain-of-thought step-by-step logic5.Context Addition: Provide relevant background informationAdvanced Optimization Strategies:Context Optimization (What model needs know)- Retrieval Augmented Generation (RAG): Grounding data sources- Prompt Engineering: Optimize patterns- Combined Strategies: Mix approaches- Fine-tuning: Extend training examples Model Optimization (How model needs act)## Model Comparison Framework| Aspect | LLMs | SLMs ||--------|------|------||Use Cases| Deep reasoning, complex content | Common NLP tasks ||Resources| High compute requirements | Edge device compatible ||Cost| Higher operational cost | Cost-effective ||Speed| Slower processing | Faster response times ||Examples| GPT-4, Mistral Large | Phi3, Mistral OSS || Aspect |
| Edge device compatible ||Cost| Higher operational cost | Cost-effective ||Speed| Slower processing | Faster response times ||Examples| GPT-4, Mistral Large | Phi3, Mistral OSS || Aspect | Proprietary | Open-Source ||--------|-------------|-------------||Performance| Cutting-edge, enterprise support | Flexible, customizable ||Control| Limited customization | Full control, fine-tuning ||Security| Built-in enterprise features | Self-managed ||Cost| Higher licensing | Cost-effective |## Best Practices & Considerations### Transformer Architecture Foundation-Parallel Processing: Words processed independently using attention mechanism-Positional Encoding: Maintains word position information sentences- Based "Attention need" paper (Vaswani et al., 2017)### Model Selection Best Practices1. Start task requirements (text-only vs multi-modal)2. Consider precision needs (base vs fine-tuned)3. Evaluate deployment constraints (local vs cloud)4. Test benchmarks production5. Plan scaling prototype
task requirements (text-only vs multi-modal)2. Consider precision needs (base vs fine-tuned)3. Evaluate deployment constraints (local vs cloud)4. Test benchmarks production5. Plan scaling prototype production### Prompt Engineering Guidelines- Use system prompts set model behavior- Apply one-shot/few-shot examples pattern recognition- Request specific output formats templates- Implement chain-of-thought complex reasoning- Add grounding context accuracy (RAG pattern)### Performance Optimization- Start prompt engineering (lowest cost/complexity)- Consider RAG grounding responses data- Use fine-tuning necessary- Combine strategies optimal results- Monitor iterate based metrics## Exam Simulation QuestionsQ: Which models best tasks requiring deep reasoning extensive context understanding?Large Language Models (LLMs) like GPT-4, Mistral Large, Llama3 70BQ: What technique involves using data source provide grounding context prompts?Retrieval Augmented Generation (RAG)Q: Which benchmark
Language Models (LLMs) like GPT-4, Mistral Large, Llama3 70BQ: What technique involves using data source provide grounding context prompts?Retrieval Augmented Generation (RAG)Q: Which benchmark measures whether model output flows smoothly resembles human language?CoherenceQ: What four key criteria selecting best language model?Task type, Precision, Openness, DeploymentQ: Which deployment option best open-source models custom requirements?Managed computeQ: What prompt engineering pattern helps models provide step-by-step explanations?Chain-of-thought (asking reasoning explanation)Q: Which models ideal edge devices limited resources?Small Language Models (SLMs) like Phi3, Mistral OSSQ: What unique identifier format deploying model Azure AI Foundry?
