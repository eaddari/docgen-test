[H1] Development Lifecycle Large Language Model (LLM) Application## Problem You want build deploy robust LLM-based application (e.g., classifying news articles). How structure development process ensure quality, scalability, maintainability?## Solution Azure FollowLLM application development lifecycle, includes four iterative stages:1. Initialization2. Experimentation3. Evaluation refinement4. Production## Required Components - Sample dataset (small large)- Prompt design- Flow design (e.g., using Prompt Flow)- Monitoring tools production## Architecture / Development ### 1. Initialization -Define objective(e.g., classify news articles categories) -Collect sample dataset(diverse, representative, privacy-compliant) -Build basic prompt-Design flow(how input processed output generated)### 2. Experimentation - Run flow sample dataset - Evaluate prompt performance - If results unsatisfactory, modify prompt flow - Iterate results acceptable### 3. Evaluation Refinement - Test flow larger dataset - Assess generalization identify bottlenecks - Refine flow re-test smaller datasets scaling - Repeat solution robust### 4. Production - Optimize flow performance - Deploy flow endpoint - Monitor usage collect feedback - Continuously improve based real-world performance## Best Practices / Considerations - Ensure datasets diverse anonymized - Use small datasets quick iteration refinement - Monitor deployed flows detect drift performance issues - Be prepared revert experimentation needed## Sample Exam Questions 1.Which phase involves defining use case designing solution?A. Experimentation B. Initialization C. Production D. RefinementCorrect Answer:B2.What purpose experimentation phase?A. Deploy application B. Collect user feedback C. Test refine flow using sample dataset D. Monitor performanceCorrect Answer:C3.Why test changes small dataset using large one?A. Its accurate B. Its faster helps catch issues early C. Its required Azure D. It avoids overfittingCorrect Answer:B# Core Components Flow Types Prompt Flow## Problem You want build LLM application using Prompt Flow Azure AI Foundry. How structure flow choose right tools flow type?## Solution Azure UsePrompt Flow, feature Azure AI Foundry, create executable workflows (flows) composed inputs, nodes (tools), outputs. Choose appropriateflow typebased application needs: standard, chat, evaluation.## Required Components -Inputs: Data passed flow (e.g., strings, integers, booleans) -Nodes: Tools perform tasks (e.g., LLM, Python, Prompt tools) -Outputs: Results produced flow -Flow types: Standard, Chat, Evaluation## Architecture / Development ### Flow Structure -Inputs: Define data flow receive -Nodes: Add tools perform operations -LLM Tool: For custom prompt execution using LLMs -Python Tool: For executing custom Python scripts -Prompt Tool: For preparing formatting prompts -Outputs: Define flow return### Node Connectivity - Nodes use: - Flow-level inputs - Outputs nodes - You reuse tools chain nodes build complex logic### Flow Types -Standard Flow: General-purpose LLM applications -Chat Flow: Designed conversational agents -Evaluation Flow: Used assess improve model performance## Best Practices / Considerations - Use appropriate tool task - Define clear input/output interfaces node - Use evaluation flows iteratively improve application - Create custom tools built-in tools dont meet needs## Sample Exam Questions 1.Which component represents processing step prompt flow?A. Input B. Node C. Output D. DatasetCorrect Answer:B2.What purpose Prompt Tool flow?A. To execute Python code B. To call external APIs C. To prepare prompts LLMs D. To monitor flow performanceCorrect Answer:C3.Which flow type best suited evaluating model performance?A. Standard Flow B. Chat Flow C. Evaluation Flow D. Custom FlowCorrect Answer:C# Explore Connections Runtimes Prompt Flow## Problem You want LLM application interact external services (e.g., Azure OpenAI, Azure AI Search) run reliably controlled compute environment. How securely configure integrations execute flows?## Solution Azure UsePrompt Flow connectionssecurely link flow external services,Prompt Flow runtimesprovide compute environment needed run flows.## Required Components -Connectionsexternal services (e.g., Azure OpenAI, Azure AI Search) -Runtimes: Compute + Environment -Azure Key Vault(for secure credential storage)## Architecture / Development ### Connections - Secure links Prompt Flow external services - Store credentials (e.g., API keys, endpoints) securely Azure Key Vault - Required tools access external APIs services| Connection Type | Required By Tools ||-------------------|-------------------------------|| Azure OpenAI | LLM, Python || OpenAI | LLM, Python || Azure AI Search | Vector DB Lookup, Python || Serp | Serp API, Python || Custom | Python |- Connections automate credential management enable secure data transfer - Reusable across multiple flows### Runtimes - Aruntime= Compute instance + Environment -Compute: Provides resources run flow -Environment: Defines packages libraries needed - Default environment available quick testing - Custom environments created specific dependencies## Best Practices / Considerations - Always configure required connections running flows - Use Azure Key Vault avoid exposing secrets - Use default runtime development; switch custom environments production - Monitor runtime performance resource usage## Sample Exam Questions 1.What purpose connection Prompt Flow?A. To define flow's output B. To store datasets C. To securely link external services D. To monitor runtime performanceCorrect Answer:C2.Which component defines packages libraries needed run flow?A. Connection B. Node C. Environment D. DatasetCorrect Answer:C3.Where secrets like API keys stored using connections?A. In flow definition B. In Azure Key Vault C. In runtime D. In tool configurationCorrect Answer:B# Explore Variants Monitoring Options Prompt Flow## Problem You want optimize LLM application's performance ensure meets real-world expectations. How fine-tune flow, deploy real-time use, monitor effectiveness?## Solution Azure Usevariantsoptimize LLM tool nodes,deploy flows endpointsreal-time integration,monitor evaluation metricsassess improve performance.## Required Components - LLM tool variant support - Online endpoint deployment - Evaluation metrics (e.g., groundedness, relevance, fluency) - End-user feedback ground truth data## Architecture / Development ### Variants -Definition: Versions LLM tool node different prompt content connection settings -Use cases: Summarization, classification, etc. -Benefits: - Improve generation quality - Simplify prompt tuning version tracking - Enable side-by-side comparisons - Increase productivity faster iteration### Deployment Endpoint - Deploy flowonline endpointintegrate external applications - Prompt Flow generates: -URLAPI access -Keysecure invocation - Real-time execution flows (e.g., chat agentic responses)### Monitoring Evaluation Metrics -Purpose: Ensure LLM output meets quality standards -Methods: - Collect end-user feedback - Compare predictions ground truth -Key Metrics: -Groundedness: Alignment source data -Relevance: Pertinence input -Coherence: Logical flow readability -Fluency: Grammatical correctness -Similarity: Semantic match expected output## Best Practices / Considerations - Use variants test compare prompt strategies - Deploy thorough evaluation - Monitor flows continuously using metrics feedback - Revert experimentation performance drops## Sample Exam Questions 1.What variant Prompt Flow?A. A different flow type B. A version tool node distinct settings C. A runtime configuration D. A deployment environmentCorrect Answer:B2.Which metric evaluates well LLM output aligns source data?A. Fluency B. Groundedness C. Coherence D. SimilarityCorrect Answer:B3.What happens deploy flow endpoint?A. It becomes read-only B. It converted Python script C. It invoked via URL key D. It automatically optimizedCorrect Answer:C