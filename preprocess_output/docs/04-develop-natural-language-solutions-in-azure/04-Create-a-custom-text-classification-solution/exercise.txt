[H1] Custom Text Classification Lab (Azure AI Language Service)## ProblemYou need build, train, deploy, test custom text classification model using Azure AI Language, including:- Provisioning service- Preparing labeling data- Training deploying model- Consuming model client application## Solution AzureUseAzure AI Language Service - Custom Text Classificationvia:-Azure portal & Language Studioconfiguration, data labeling, model training-Azure SDK (C# / Python)consume model client application## Components Required- Azure AI Language resource (Custom text classification enabled)- Azure Storage account (blob storage)- Language Studio- Role assignment:Storage Blob Data Contributor- Sample data (from Visual Studio Code with: - Azure AI Text Analytics SDK (Azure.AI.TextAnalytics 5.3.0) - Git clone repository Architecture / Development### 1 Provision Azure AI Language Resource- Create new Language resource Azure portal- EnableCustom text classification & extraction- Choose supported region (e.g. East US, West Europe, UK South...)- Pricing tier: F0 (free) S (standard)- Create new Storage account (Standard LRS)- Assign role:Storage Blob Data Contributoruser### 2 Upload Training Data- Download sample data: Upload blob container namedarticles(anonymous read access enabled)### 3 Create Project Language Studio- Resource: Select previously created Azure AI Language resource- Project type:Single label classification- Project name:ClassifyLab- Language:English (US)- Use storage containerarticles- Choose option label files part project### 4 Label DataDefine 4 classes:Classifieds,Sports,News,Entertainment.Assign documents manually training testing dataset:| Article | Class | Dataset ||---------|-------|---------|| Article 1 | Sports | Training || Article 10 | News | Training || Article 11 | Entertainment | Testing || Article 12 | News | Testing || Article 13 | Sports | Testing || Article 2 | Sports | Training || Article 3 | Classifieds | Training || Article 4 | Classifieds | Training || Article 5 | Entertainment | Training || Article 6 | Entertainment | Training || Article 7 | News | Training || Article 8 | News | Training || Article 9 | Entertainment | Training |Save labels.### 5 Train Model- Model name:ClassifyArticles- Split type:Manual split- Start training- Wait completion### 6 Evaluate Model- Review performance metrics (precision, recall, F1 score)- UseModel performanceTest set detailsanalyze errors- Toggle "Show mismatches only" evaluation### 7 Deploy Model- Deployment name:articles- DeployClassifyArticlesmodel### 8 Develop Client ApplicationClone repo:bash project VS Code (`Labfiles/04-text-classification/classify-text`).Install SDK:**C#:**bashdotnet add package Azure.AI.TextAnalytics --version 5.3.0**Python:**bashpip install azure-ai-textanalytics==5.3.0Configure app settings:- **C#**: `appsettings.json`- **Python**: `.env`Set: `aiSvcKey`, `aiSvcEndpoint`, `projectName`, `deploymentName`.### 9 Add Code Classify Documents#### Import namespaces:**C#:**csharpusing Azure;using Azure.AI.TextAnalytics;**Python:**pythonfrom azure.core.credentials import AzureKeyCredentialfrom azure.ai.textanalytics import TextAnalyticsClient#### Create client:**C#:**csharpAzureKeyCredential credentials = new AzureKeyCredential(aiSvcKey);Uri endpoint = new Uri(aiSvcEndpoint);TextAnalyticsClient aiClient = new TextAnalyticsClient(endpoint, credentials);**Python:**pythoncredential = AzureKeyCredential(ai_key)ai_client = TextAnalyticsClient(endpoint=ai_endpoint, credential=credential)#### Get classifications:**C#:**csharpClassifyDocumentOperation operation = await aiClient.SingleLabelClassifyAsync( WaitUntil.Completed, batchedDocuments, projectName, deploymentName);**Python:**pythonoperation = ai_client.begin_single_label_classify( batchedDocuments, project_name=project_name, deployment_name=deployment_name)document_results = operation.result()### Test ApplicationRun app:**C#:**bashdotnet run**Python:**bashpython classify-text.py```Output:Shows predicted class confidence score document.## Best Practice / Considerations- Ensure correct role assignments (Storage Blob Data Contributor) avoid authorization errors- Use manual split small datasets control class balance- Review test set mismatches improve model- Secure blob storage access production (avoid anonymous access)- API keys must stored securely never hard-coded## Exam-like Sample Questions### Question 1:Which role must assigned user storage access project creation?A. Storage Blob Data Owner B. Storage Blob Data Contributor C. ReaderAnswer: B### Question 2:Which access level configured container uploading training data?A. Private B. Blob (anonymous read access blobs only) C. Container (anonymous read access containers blobs)Answer: C### Question 3:Which split option recommended small datasets?A. Automatic split B. Manual splitAnswer: B### Question 4:Which deployment name used lab?A. articles B. classifyLab C. classifyArticlesAnswer: A### Question 5:Which SDK version used Azure Text Analytics Client?A. 4.2.0 B. 5.3.0 C. 3.1.0Answer: B